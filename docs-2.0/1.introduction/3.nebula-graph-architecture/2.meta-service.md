# Meta服务

本文介绍Meta服务的架构和功能。

## Meta服务架构

![The architecture of the Meta Service](https://docs-cdn.nebula-graph.com.cn/docs-2.0/1.introduction/2.nebula-graph-architecture/meta-architecture1.png)

Meta服务是由nebula-metad进程提供的，用户可以根据场景配置nebula-metad进程数量：

- 测试环境中，可以在Nebula Graph集群中部署1个或3个nebula-metad进程。如果要部署3个，可以将它们部署在1台机器上，或者分别部署在不同的机器上。
- 生产环境中，建议在Nebula Graph集群中部署3个nebula-metad进程。需将这些进程部署在不同的机器上以保证高可用。

所有 nebula-metad 进程构成了基于 [Raft](https://raft.github.io/) 协议的集群。

!!! Note “关于 Raft 的简单介绍”

    分布式系统中，同一份数据通常会有多个副本，这样即使少数副本发生故障，系统仍可正常运行。这就需要一定的技术手段来保证多个副本之间的一致性。
    
    基本原理：Raft 就是一种用于保证多副本一致性的协议。Raft 采用多个副本之间竞选的方式，赢得”超过半数”副本投票的(候选)副本成为 Leader，由 Leader 代表所有副本对外提供服务；其他 Follower 作为备份。当该 Leader 出现异常后(通信故障、运维命令等)，其余 Follower 进行新一轮选举，投票出一个新的 Leader。Leader 和 Follower 之间通过心跳的方式相互探测是否存活,并以 Raft-wal 的方式写入硬盘，超过多个心跳仍无响应的副本会被认为发生故障。
    
    读写流程：对于客户端的每个写入请求，Leader 会将该写入以 Raft-wal 的方式，将该条同步给其他 Follower，并只有在“超过半数”副本都成功收到 Raft-wal 后，才会返回客户端该写入成功。对于客户端的每个读取请求，都直接访问 Leader，而 Follower 并不参与读请求服务。
    
    故障流程：如果系统只有一个副本时，其自身就是 Leader；如果其发生故障，系统将完全不可用。如果系统有 3 个副本，其中一个副本是 Leader，其他 2 个副本是 Follower；即使原 Leader 发生故障，剩下两个副本仍可投票出一个新的Leader（以及一个Follower），此时系统仍可使用；但是当这2个副本中任一者再次发生故障后，由于投票人数不足，系统将完全不可用。

## Meta服务功能

### 管理用户账号

Meta服务中存储了用户的账号和权限信息，当客户端通过账号发送请求给Meta服务，Meta服务会检查账号信息，以及该账号是否有对应的请求权限。

更多Nebula Graph的访问控制说明，请参见[身份验证](../../7.data-security/1.authentication/1.authentication.md)。

### 管理分片

Meta服务负责存储和管理分片的位置信息，并且保证分片的负载均衡。

### 管理图空间

Nebula Graph支持多个图空间，不同图空间内的数据是安全隔离的。Meta服务存储所有图空间的元数据（非完整数据），并跟踪数据的变更，例如增加或删除图空间。

### 管理Schema信息

Nebula Graph是强类型图数据库，它的Schema包括标签、边类型、标签属性和边类型属性。

Meta服务中存储了Schema信息，同时还负责Schema的添加、修改和删除，并记录它们的版本。

更多Nebula Graph的Schema信息，请参见[数据模型](../2.data-model.md)。

### 管理基于TTL的数据回收

Meta服务提供基于TTL（time to live）的自动数据回收和空间回收。

### 管理作业

Meta服务中的作业管理模块负责作业的创建、排队、查询和删除。
